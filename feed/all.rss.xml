<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Vlad Niculae (~vene)</title><link>http://vene.ro/</link><description></description><lastBuildDate>Fri, 04 Mar 2016 12:00:00 +0100</lastBuildDate><item><title>Winning Arguments and Attitude Change on Reddit</title><link>http://vene.ro/blog/winning-arguments-attitude-change-reddit-cmv.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;&lt;em&gt;I have the honor of featuring another guest post on my blog. This time, we have with us my friend &lt;a href="https://chenhaot.com"&gt;Chenhao Tan&lt;/a&gt;. We recently collaborated on &lt;a href="https://chenhaot.com/pages/changemyview.html"&gt;an effort to understand how people change their minds&lt;/a&gt; on the &lt;a href="http://reddit.com/r/changemyview"&gt;&lt;code&gt;/r/ChangeMyView&lt;/code&gt;&lt;/a&gt;&amp;nbsp;subreddit.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/github/vene/vene.github.io/blob/pelican/content/blog/winning_arguments.ipynb"&gt;Source of this Jupyter&amp;nbsp;Notebook.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;One of the many reasons why people are beautiful and fascinating is the way we change.  I get reminded of how much I have changed everytime I see a photo of myself from high school, and this always triggers memories of how my opinions and attitudes have changed over the years. Some of the beliefs I held most strongly ended up being abandonded completely, while others have not changed much. &lt;span style="color: red"&gt;*If you&amp;#8217;re bored already, scroll down, this blog post has code&amp;nbsp;too!*&lt;/span&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene &amp; Chenhao Tan</dc:creator><pubDate>Fri, 04 Mar 2016 12:00:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2016-03-04:/blog/winning-arguments-attitude-change-reddit-cmv.html</guid><category>persuasion</category><category>malleability</category><category>attitude change</category><category>reddit</category><category>social</category></item><item><title>Word Mover’s Distance in Python</title><link>http://vene.ro/blog/word-movers-distance-in-python.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Word-mover's-distance-classification-in-Python"&gt;Word mover&amp;#8217;s distance classification in Python&lt;a class="anchor-link" href="#Word-mover's-distance-classification-in-Python"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;&lt;em&gt;A guide to scikit-learn compatible nearest neighbors classification using the recently introduced word mover&amp;#8217;s distance (&lt;span class="caps"&gt;WMD&lt;/span&gt;). &lt;/em&gt;
Joint post with the awesome &lt;a href="http://matthewkusner.com"&gt;Matt Kusner&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;a href="http://nbviewer.jupyter.org/github/vene/vene.github.io/blob/pelican/content/blog/word-movers-distance-in-python.ipynb"&gt;Source of this Jupyter&amp;nbsp;notebook.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In document classification and other natural language processing applications, having a good measure of the similarity of two texts can be a valuable building block.   Ideally, such a measure would capture semantic information.  Cosine similarity on bag-of-words vectors is known to do well in practice, but it inherently cannot capture when documents say the same thing in completely different&amp;nbsp;words.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene &amp; Matt Kusner</dc:creator><pubDate>Sat, 07 Nov 2015 12:00:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2015-11-07:/blog/word-movers-distance-in-python.html</guid><category>word embeddings</category><category>text classification</category><category>earth mover's distance</category></item><item><title>Flask-SocketIO on OpenShift: fallback on another port</title><link>http://vene.ro/blog/flask-socketio-openshift-fallback-xhr-polling.html</link><description>&lt;h2&gt;&lt;span class="caps"&gt;TL&lt;/span&gt;; &lt;span class="caps"&gt;DR&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;I hacked the &lt;a href="https://gist.github.com/vene/c0657d854ae74a4511d2"&gt;SocketIO client
0.9.16&lt;/a&gt; to support
specifying a special port (&lt;code&gt;wsport&lt;/code&gt;) to use only for the WebSocket protocol,
while keeping all other traffic on the default port. This is required by setups
such as OpenShift which require WebSocket traffic to come over a different …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 06 Jul 2015 00:00:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2015-07-06:/blog/flask-socketio-openshift-fallback-xhr-polling.html</guid><category>flask-socketio</category><category>flask</category><category>socketio</category><category>openshift</category></item><item><title>Kemeny-Young Optimal Rank Aggregation in Python</title><link>http://vene.ro/blog/kemeny-young-optimal-rank-aggregation-in-python.html</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Rank aggregation is a problem with many important applications and naive approaches to it go wrong in subtle&amp;nbsp;ways.&lt;/p&gt;
&lt;p&gt;Let&amp;#8217;s say that your national Quidditch league is dominated by five major wizard sports newspapers. Yes, the ones with moving images and everything.  Every week after the games, each of them publishes a ranking of the star players.  For now, let&amp;#8217;s suppose that the set of players under investigation is always the same, as the problem becomes a bit more complicated&amp;nbsp;otherwise.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Wed, 22 Jan 2014 18:00:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2014-01-22:/blog/kemeny-young-optimal-rank-aggregation-in-python.html</guid><category>python</category><category>rank aggregation</category><category>kendall</category><category>tau</category><category>kemeny</category><category>kemeny-young</category><category>voting theory</category></item><item><title>Site move</title><link>http://vene.ro/blog/site-move.html</link><description>&lt;p&gt;I finally got around to moving my entire website, including the blog,
to &lt;a href="http://getpelican.com"&gt;Pelican&lt;/a&gt;.  I probably would have gotten away with it
too if it weren&amp;#8217;t for those meddling kids who hacked my friend&amp;#8217;s server and
convinced me that it&amp;#8217;s worth the effort to go&amp;nbsp;static.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It …&lt;/strong&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 10 Jan 2014 12:00:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2014-01-10:/blog/site-move.html</guid><category>pelican</category><category>blog</category></item><item><title>BibTeX-powered publications list for Pelican with pelican-bibtex</title><link>http://vene.ro/blog/bibtex-powered-publications-list-for-pelican-with-pelican-bibtex.html</link><description>&lt;h2&gt;Hook&lt;/h2&gt;
&lt;p&gt;Wouldn&amp;#8217;t you like to manage your academic publications list easily
within the context of your static website? Without resorting to external
services, or to software like &lt;em&gt;bibtex2html&lt;/em&gt;, which is very nice but will
then require restyling to fit your&amp;nbsp;templates?&lt;/p&gt;
&lt;p&gt;Look no more, with the help of &lt;a href="https://github.com/vene/pelican-bibtex"&gt;pelican-bibtex …&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 22 Apr 2013 10:45:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2013-04-22:/blog/bibtex-powered-publications-list-for-pelican-with-pelican-bibtex.html</guid><category>bibtex</category><category>blog</category><category>citations</category><category>pelican</category><category>publications</category><category>pybtex</category><category>references</category><category>static blog</category><category>static website</category><category>Uncategorized</category></item><item><title>Really the most common english idioms?</title><link>http://vene.ro/blog/really-most-common-english-idioms.html</link><description>&lt;p&gt;A while back I ran into &lt;a href="http://voxy.com/blog/index.php/2012/02/top-10-most-common-idioms-in-english/"&gt;this blog post&lt;/a&gt; and it made me wonder. I&amp;#8217;m
not a native speaker but the idiomatic phrases that they note as common
don&amp;#8217;t strike me as such. I don&amp;#8217;t think I have ever encountered them very
often in real&amp;nbsp;dialogue.&lt;/p&gt;
&lt;p&gt;The …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 11 Feb 2013 16:50:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2013-02-11:/blog/really-most-common-english-idioms.html</guid><category>bnc</category><category>british national corpus</category><category>corpus</category><category>fixed expression</category><category>fixed phrase</category><category>idioms</category><category>oec</category><category>oxford english corpus</category><category>corpus linguistics</category><category>nlp</category></item><item><title>Scikit-learn-speed: An overview on the final day</title><link>http://vene.ro/blog/scikit-learn-speed-an-overview-on-the-final-day.html</link><description>&lt;p&gt;This summer, I was granted the project called &lt;em&gt;scikit-learn-speed&lt;/em&gt;,
consisting of developing a benchmarking platform for &lt;em&gt;scikit-learn&lt;/em&gt; and
using it to find potential speedups, and in the end, make the library go
faster wherever I&amp;nbsp;can.&lt;/p&gt;
&lt;p&gt;On the official closing day of this work, I&amp;#8217;d like to take a …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 20 Aug 2012 02:44:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-08-20:/blog/scikit-learn-speed-an-overview-on-the-final-day.html</guid><category>gsoc</category><category>optimization</category><category>scikit-learn-speed</category><category>speedup</category><category>summary</category><category>vbench</category><category>benchmarking</category><category>python</category><category>scikit-learn</category></item><item><title>Inverses and pseudoinverses. Numerical issues, speed, symmetry.</title><link>http://vene.ro/blog/inverses-pseudoinverses-numerical-issues-speed-symmetry.html</link><description>&lt;p&gt;The matrix inverse is a cornerstone of linear algebra, taught, along
with its applications, since high school. The inverse of a matrix
\$latex A\$, if it exists, is the matrix \$latex A\^{-1}\$ such that
\$latex &lt;span class="caps"&gt;AA&lt;/span&gt;\^{-1} = A\^{-1}A = I_n\$. Based on the requirement that the
left and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sat, 18 Aug 2012 19:41:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-08-18:/blog/inverses-pseudoinverses-numerical-issues-speed-symmetry.html</guid><category>inv</category><category>matrix inverse</category><category>numerical analysis</category><category>numerical methods</category><category>pinv</category><category>pinvh</category><category>positive semidefinite</category><category>pseudoinverse</category><category>symmetric</category><category>benchmarking</category><category>python</category></item><item><title>The scikit-learn-speed ship has set sail! Faster than ever, with multi-step benchmarks!</title><link>http://vene.ro/blog/the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks.html</link><description>&lt;p&gt;I am pleased to announce that last night at 2:03 &lt;span class="caps"&gt;AM&lt;/span&gt;, the first fully
automated run of the scikit-learn-speed test suite has run on our
Jenkins instance! You can admire it at &lt;a href="http://jenkins-scikit-learn.github.com/scikit-learn-speed/"&gt;its temporary home&lt;/a&gt; for now.
As soon as we verify that everything is good, we will move …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sat, 11 Aug 2012 17:32:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-08-11:/blog/the-scikit-learn-speed-ship-has-set-sail-faster-than-ever-with-multi-step-benchmarks.html</guid><category>multi-step</category><category>multistep</category><category>vbench</category><category>benchmarking</category><category>python</category><category>scikit-learn</category></item><item><title>Profiler output, benchmark standard deviation and other goodies in scikit-learn-speed</title><link>http://vene.ro/blog/profiler-output-benchmark-standard-deviation-and-other-goodies-in-scikit-learn-speed.html</link><description>&lt;p&gt;This post is about the &lt;a href="http://scikit-learn.org"&gt;scikit-learn&lt;/a&gt;benchmarking project that I am
working on, called &lt;a href="https://github.com/vene/scikit-learn-speed"&gt;scikit-learn-speed&lt;/a&gt;. This is a continuous
benchmarking suite that runs and generates &lt;span class="caps"&gt;HTML&lt;/span&gt; reports using Wes
McKinney&amp;#8217;s &lt;a href="http://wesmckinney.com/blog/?p=373"&gt;vbench&lt;/a&gt; framework, to which I had to make some (useful, I
hope)&amp;nbsp;additions.&lt;/p&gt;
&lt;h2&gt;What it looks like&amp;nbsp;now&lt;/h2&gt;
&lt;p&gt;You …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 27 Jul 2012 11:01:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-07-27:/blog/profiler-output-benchmark-standard-deviation-and-other-goodies-in-scikit-learn-speed.html</guid><category>gsoc</category><category>memory_profiler</category><category>scikit-learn-speed</category><category>vbench</category><category>benchmarking</category><category>python</category><category>scikit-learn</category></item><item><title>Scikit-learn-speed HTML reports teaser</title><link>http://vene.ro/blog/scikit-learn-speed-html-reports-teaser.html</link><description>&lt;p&gt;&lt;span class="caps"&gt;EDIT&lt;/span&gt;: I made the plots a little more readable, check it&amp;nbsp;out!&lt;/p&gt;
&lt;p&gt;Last time, I teased you with a screenshot of local output. Now, I will
tease you with the benchmarks run on a couple of recent commits, along
with some from earlier this&amp;nbsp;year.&lt;/p&gt;
&lt;p&gt;After some effort and bugfixes …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 20 Jul 2012 14:40:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-07-20:/blog/scikit-learn-speed-html-reports-teaser.html</guid><category>gsoc</category><category>scikit-learn-speed</category><category>vbench</category><category>benchmarking</category><category>python</category><category>scikit-learn</category></item><item><title>Memory benchmarking with vbench</title><link>http://vene.ro/blog/memory-benchmarking-with-vbench.html</link><description>&lt;p&gt;The &lt;a href="https://github.com/vene/scikit-learn-speed"&gt;scikit-learn-speed project&lt;/a&gt; now has memory usage&amp;nbsp;benchmarking!&lt;/p&gt;
&lt;p&gt;This was accomplished by building on what I described in my recent
posts, specifically the extensions to Fabian&amp;#8217;s [memory_profiler][] that
you can find in &lt;a href="https://github.com/vene/memory_profiler"&gt;my fork&lt;/a&gt;, but they will be merged upstream soon. The
key element is the &lt;code&gt;%magic_memit&lt;/code&gt; function whose …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 05 Jul 2012 12:38:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-07-05:/blog/memory-benchmarking-with-vbench.html</guid><category>memit</category><category>memory</category><category>vbench</category><category>python</category><category>scikit-learn</category></item><item><title>On why my %memit fails on OSX</title><link>http://vene.ro/blog/on-why-my-memit-fails-on-osx.html</link><description>&lt;p&gt;In my &lt;a href="http://localhost:8001/2012/07/02/more-on-memory-benchmarking/" title="More on memory benchmarking"&gt;last post&lt;/a&gt; I mentioned that I&amp;#8217;m not satisfied with the current
state of &lt;code&gt;%memit&lt;/code&gt;, because some more complicated numerical function
calls make it crash. I will start this post with a reminder of a pretty
important&amp;nbsp;bug:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[On MacOS X (10.7 but maybe more), after forking …&lt;/strong&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Wed, 04 Jul 2012 12:49:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-07-04:/blog/on-why-my-memit-fails-on-osx.html</guid><category>IPython</category><category>magic</category><category>memit</category><category>mprun</category><category>benchmarking</category><category>python</category></item><item><title>More on memory benchmarking</title><link>http://vene.ro/blog/more-on-memory-benchmarking.html</link><description>&lt;p&gt;Following up on my task to make it easier to benchmark memory usage in
Python, I updated Fabian&amp;#8217;s [memory_profiler][] to include a couple of
useful IPython magics. While in my &lt;a href="http://localhost:8001/2012/06/30/quick-memory-usage-benchmarking-in-ipython/" title="Quick memory usage benchmarking in IPython"&gt;last post&lt;/a&gt;, I used the new IPython
0.13 syntax for defining magics, this time I used the
backwards-compatible …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 02 Jul 2012 11:27:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-07-02:/blog/more-on-memory-benchmarking.html</guid><category>IPython</category><category>magic</category><category>memit</category><category>memory</category><category>memory_profiler</category><category>mprun</category><category>benchmarking</category><category>python</category></item><item><title>Quick memory usage benchmarking in IPython</title><link>http://vene.ro/blog/quick-memory-usage-benchmarking-in-ipython.html</link><description>&lt;p&gt;Everybody loves &lt;code&gt;%timeit&lt;/code&gt;, there&amp;#8217;s no doubt about it. So why not have
something like that, but for measuring how much memory your line takes?
Well, now you can; grab a hold of the script in the following gist and
run it like in the&amp;nbsp;example.&lt;/p&gt;
&lt;p&gt;[gist&amp;nbsp;id=3022718]&lt;/p&gt;
&lt;p&gt;Instead …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sat, 30 Jun 2012 08:53:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-06-30:/blog/quick-memory-usage-benchmarking-in-ipython.html</guid><category>benchmark</category><category>IPython</category><category>magic</category><category>memory</category><category>memory_profiler</category><category>profiling</category><category>benchmarking</category><category>python</category></item><item><title>Compiling and Installing GLARF and the bundled Charniak parser on MacOS X</title><link>http://vene.ro/blog/compiling-and-installing-glarf-and-the-bundled-charniak-parser-on-macos-x.html</link><description>&lt;p&gt;It seems that I keep getting handed buggy code to install. These are
cases of research software where the developers didn&amp;#8217;t make the effort
to make sure their tool works on the platforms it&amp;nbsp;should.&lt;/p&gt;
&lt;p&gt;[&lt;span class="caps"&gt;GLARF&lt;/span&gt;][] (Grammatical and Logical Argument Representation Framework)
is, in their words, &amp;#8220;a typed feature …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 21 Jun 2012 12:32:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-06-21:/blog/compiling-and-installing-glarf-and-the-bundled-charniak-parser-on-macos-x.html</guid><category>bllip</category><category>charniak</category><category>glarf</category><category>installation</category><category>parser</category><category>nlp</category></item><item><title>Compiling MegaM on MacOS X</title><link>http://vene.ro/blog/compiling-megam-on-macos-x.html</link><description>&lt;p&gt;&lt;a href="http://hal3.name/megam"&gt;MegaM&lt;/a&gt; is Hal Daumé &lt;span class="caps"&gt;III&lt;/span&gt;&amp;#8217;s maxent (logistic regression, and much more)
modeling software written in OCaml. It is feature-packed and seems to be
used a lot, despite being slightly dated. &lt;a href="http://nltk.org" title="Natural Language Toolkit"&gt;&lt;span class="caps"&gt;NLTK&lt;/span&gt;&lt;/a&gt; is able to use&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;In order to compile it as of 2012, with the current version of …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 08 Jun 2012 11:45:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-06-08:/blog/compiling-megam-on-macos-x.html</guid><category>compile</category><category>install</category><category>maxent</category><category>megam</category><category>nlp</category></item><item><title>Dynamically generated benchmarks with vbench</title><link>http://vene.ro/blog/dynamically-generated-benchmarks-with-vbench.html</link><description>&lt;p&gt;To construct a &lt;code&gt;vbench&lt;/code&gt; benchmark you need a setup string and a code
string. The constructor&amp;#8217;s signature&amp;nbsp;is:  &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Benchmark(self, code, setup, ncalls=None, repeat=3, cleanup=None, name=None, description=None, start_date=None, logy=False)&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Why generate benchmarks&amp;nbsp;dynamically?&lt;/h2&gt;
&lt;p&gt;For most &lt;code&gt;scikit-learn&lt;/code&gt; purposes, the &lt;code&gt;code&lt;/code&gt; string will be …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 07 Jun 2012 01:57:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-06-07:/blog/dynamically-generated-benchmarks-with-vbench.html</guid><category>gsoc</category><category>vbench</category><category>benchmarking</category><category>python</category></item><item><title>First contact with vbench</title><link>http://vene.ro/blog/first-contact-with-vbench.html</link><description>&lt;p&gt;With a slight delay caused by going to lovely lovely Istanbul for the
&lt;span class="caps"&gt;LREC&lt;/span&gt; conference where I presented a &lt;a href="http://vene.ro/papers/lrec12-poster.pdf"&gt;poster&lt;/a&gt;, I am back to work on the
Google Summer of Code project. By the way, this year&amp;#8217;s logo and swag
looks a lot nicer than last year&amp;#8217;s, thank …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Tue, 29 May 2012 12:57:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-05-29:/blog/first-contact-with-vbench.html</guid><category>benchmarks</category><category>perf.py</category><category>performance</category><category>vbench</category><category>scikit-learn</category></item><item><title>Support vector regression on Anscombe’s dataset</title><link>http://vene.ro/blog/support-vector-regression-on-anscombes-dataset.html</link><description>&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Anscombe's_quartet" title="Anscombe's quartet"&gt;Anscombe&amp;#8217;s quartet&lt;/a&gt; is a set of four toy datasets that look very
different, but many of their statistics coincide. They were developed by
Francis Anscombe as a striking visual to show that even for small
datasets, blindly examining their statistical properties without
considering their structure can&amp;nbsp;mislead.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Anscombe's datasets" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/640px-Anscombe%27s_quartet_3.svg.png"&gt;&lt;/p&gt;
&lt;p&gt;Particularly, the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 27 May 2012 21:59:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-05-27:/blog/support-vector-regression-on-anscombes-dataset.html</guid><category>anscombe</category><category>outlier</category><category>robust regression</category><category>support vector regression</category><category>svm</category><category>svr</category><category>python</category><category>scikit-learn</category></item><item><title>GSoC 2012 proposal: Need for scikit-learn speed</title><link>http://vene.ro/blog/gsoc-2012-proposal-need-for-scikit-learn-speed.html</link><description>&lt;p&gt;This summer I hope to be able to put in another full-time amount of
effort into scikit-learn. After a successful Google Summer of Code
project last year on dictionary learning, I now plan to do some
low-level work. The title of my proposal is: &amp;#8220;Need for scikit-learn
speed&amp;#8221; and, in …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 16 Apr 2012 00:37:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-04-16:/blog/gsoc-2012-proposal-need-for-scikit-learn-speed.html</guid><category>gsoc</category><category>proposal</category><category>scikit-learn</category></item><item><title>Romanian people and coffee</title><link>http://vene.ro/blog/romanian-people-and-coffee.html</link><description>&lt;p&gt;So I got my hands of the &lt;a href="http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html" title="Google Research"&gt;Google N-gram data&lt;/a&gt; for the Romanian
language. It&amp;#8217;s noisy as hell, has some other subtle issues too, but
here&amp;#8217;s the first thing I&amp;nbsp;noticed:&lt;/p&gt;
&lt;p&gt;The Romanian word for coffee is &lt;em&gt;cafea&lt;/em&gt;, and the more you crave it, the
longer you pronunce …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 13 Apr 2012 21:20:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2012-04-13:/blog/romanian-people-and-coffee.html</guid><category>Uncategorized</category><category>coffee</category><category>ngram</category></item><item><title>Nash-Williams theorem on the Hamiltonian property of some regular graphs</title><link>http://vene.ro/blog/nash-williams-theorem-on-the-hamiltonian-property-of-some-regular-graphs.html</link><description>&lt;p&gt;I have been digging on the internet for the proof of this theorem for
the last couple of days without success. The result was published by Sir
Crispin Nash-Williams as &lt;em&gt;Valency Sequences which force graphs to have
Hamiltonian Circuits&lt;/em&gt;. Interim Rep, University of Waterloo Res Rep.,
Waterloo, Ontario, 1969. However …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 29 Jan 2012 22:31:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2012-01-29:/blog/nash-williams-theorem-on-the-hamiltonian-property-of-some-regular-graphs.html</guid><category>graph</category><category>graph theory</category><category>hamiltonian</category><category>nash-williams</category><category>Uncategorized</category></item><item><title>Moving out</title><link>http://vene.ro/blog/moving-out.html</link><description>&lt;p&gt;Happy new year,&amp;nbsp;friends!&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve made a New Year&amp;#8217;s resolution to build a better web presence and
make better use of the domain that I previously only used for&amp;nbsp;mail.&lt;/p&gt;
&lt;p&gt;This has prompted me to move my blog over to http://localhost:8001 which
hopefully is shorter, better …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 06 Jan 2012 00:16:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2012-01-06:/blog/moving-out.html</guid><category>Uncategorized</category></item><item><title>The nasty bug crawling in my Orthogonal Matching Pursuit code</title><link>http://vene.ro/blog/the-nasty-bug-crawling-in-my-orthogonal-matching-pursuit-code.html</link><description>&lt;p&gt;A while back, Bob L. Sturm blogged about a &lt;a href="http://media.aau.dk/null_space_pursuits/2011/10/efficient-omp.html"&gt;similar implementation of
&lt;span class="caps"&gt;OMP&lt;/span&gt;&lt;/a&gt; to the one in scikit-learn. Instead of using the Cholesky
decomposition like we did, his Matlab code uses the &lt;span class="caps"&gt;QR&lt;/span&gt; decomposition, to
a similar (or maybe even identical) outcome, in theory. So lucky that
Alejandro pointed out …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 18 Nov 2011 20:51:00 +0100</pubDate><guid isPermaLink="false">tag:vene.ro,2011-11-18:/blog/the-nasty-bug-crawling-in-my-orthogonal-matching-pursuit-code.html</guid><category>bug</category><category>omp</category><category>orthogonal matching pursuit</category><category>dictionary learning</category><category>scikit-learn</category></item><item><title>Sampling Gamma random variates through the ratio-of-uniforms method</title><link>http://vene.ro/blog/sampling-gamma-random-variates-through-the-ratio-of-uniforms-method.html</link><description>&lt;p&gt;One year ago I had the chance to take a class on Monte Carlo simulation
with prof. Ion Văduva, and my assignment for the class was to implement
exactly what it says in the title of the blog post. I am going to walk
you through the idea behind&amp;nbsp;this …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 09 Oct 2011 15:40:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-10-09:/blog/sampling-gamma-random-variates-through-the-ratio-of-uniforms-method.html</guid><category>monte carlo</category><category>numpy</category><category>random sampling</category><category>ratio-of-uniforms</category><category>scipy</category><category>python</category></item><item><title>RANLP 2011 in Hissar, BG</title><link>http://vene.ro/blog/ranlp-2011-in-hissar-bg.html</link><description>&lt;p&gt;Last week was marked by the international &lt;span class="caps"&gt;RANLP&lt;/span&gt; (Recent Advances in
Natural Language Processing) conference, taking place in a nice spa in
Hissar, Bulgaria. The excellent folks from the &lt;a href="http://clg.wlv.ac.uk/"&gt;computational
linguistics group&lt;/a&gt; at the University of Wolverhampton were behind it,
together with the &lt;a href="http://www.iict.bas.bg/EN/index.html"&gt;Institute of Information and Communication
Technologies&lt;/a&gt; from …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Tue, 20 Sep 2011 14:17:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-09-20:/blog/ranlp-2011-in-hissar-bg.html</guid><category>conferences</category><category>nlp</category></item><item><title>Dictionary learning in scikit-learn 0.9</title><link>http://vene.ro/blog/dictionary-learning-in-scikit-learn-0-9.html</link><description>&lt;p&gt;Thanks to Olivier, Gaël and Alex, who reviewed the code heavily the last
couple of days, and with apologies for my lack of activity during a
sequence of conferences, Dictionary learning has officially been merged
into scikit-learn master, and just in time for the new scikit-learn 0.9
release. Here …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 19 Sep 2011 19:15:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-09-19:/blog/dictionary-learning-in-scikit-learn-0-9.html</guid><category>dictionary learning</category><category>scikit-learn</category></item><item><title>Long overdue update. EuroScipy and SSLST 2011</title><link>http://vene.ro/blog/long-overdue-update-euroscipy-and-sslst-2011.html</link><description>&lt;p&gt;Anybody reading my blog should have expected me to blog about the end of
my GSoC. Sorry to disappoint, but I simply did not experience anything
similar to an ending. On the contrary, I feel like things have barely
started. Also, I apologize for one of the few posts here …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 05 Sep 2011 00:08:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-09-05:/blog/long-overdue-update-euroscipy-and-sslst-2011.html</guid><category>Uncategorized</category></item><item><title>Optimizing Orthogonal Matching Pursuit code in Numpy, part 2</title><link>http://vene.ro/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-2.html</link><description>&lt;p&gt;&lt;span class="caps"&gt;EDIT&lt;/span&gt;: There was a bug in the final version of the code presented here.
It is fixed now, for its backstory, check out &lt;a href="http://venefrombucharest.wordpress.com/2011/11/18/the-nasty-bug-crawling-in-my-orthogonal-matching-pursuit-code/" title="The nasty bug crawling in my Orthogonal Matching Pursuit code"&gt;my blog post on it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When we last saw our hero, he was fighting with the dreaded
implementation of least-angle regression, knowing full well that it was …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 11 Aug 2011 19:39:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-08-11:/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-2.html</guid><category>blas</category><category>efficient</category><category>lapack</category><category>numpy</category><category>omp</category><category>orthogonal matching pursuit</category><category>potrs</category><category>scipy</category><category>dictionary learning</category><category>python</category><category>scikit-learn</category></item><item><title>Optimizing Orthogonal Matching Pursuit code in Numpy, part 1</title><link>http://vene.ro/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-1.html</link><description>&lt;p&gt;After intense code optimization work, my implementation of &lt;span class="caps"&gt;OMP&lt;/span&gt; finally
beat least-angle regression! This was the primary issue discussed during
the pull request, so once performance was taken care of, the code was
ready for merge. Orthogonal matching pursuit is now available in
scikits.learn as a sparse linear regression …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 07 Aug 2011 20:50:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-08-07:/blog/optimizing-orthogonal-matching-pursuit-code-in-numpy-part-1.html</guid><category>efficient</category><category>numpy</category><category>omp</category><category>orthogonal matching pursuit</category><category>scipy</category><category>dictionary learning</category><category>scikit-learn</category><category>python</category></item><item><title>Progress on Orthogonal Matching Pursuit</title><link>http://vene.ro/blog/progress-on-orthogonal-matching-pursuit.html</link><description>&lt;p&gt;Since orthogonal matching pursuit (&lt;span class="caps"&gt;OMP&lt;/span&gt;) is an important part of signal
processing and therefore crucial to the image processing aspect of
dictionary learning, I am currently focusing on optimizing the &lt;span class="caps"&gt;OMP&lt;/span&gt; code
and making sure it is stable. &lt;span class="caps"&gt;OMP&lt;/span&gt; is a forward method like least-angle
regression, so it is natural …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Tue, 02 Aug 2011 16:56:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-08-02:/blog/progress-on-orthogonal-matching-pursuit.html</guid><category>omp</category><category>orthogonal matching pursuit</category><category>scikit-learn</category></item><item><title>SparsePCA in scikits.learn-git</title><link>http://vene.ro/blog/sparsepca-in-scikits-learn-git.html</link><description>&lt;p&gt;I am happy to announce that the Sparse &lt;span class="caps"&gt;PCA&lt;/span&gt; code has been reviewed and
merged into the main &lt;code&gt;scikits.learn&lt;/code&gt; repository.&lt;/p&gt;
&lt;p&gt;You can use it if you install the bleeding edge &lt;code&gt;scikits.learn&lt;/code&gt; git
version, by first downloading the source code as explained in the
&lt;a href="http://scikit-learn.sourceforge.net/stable/developers/index.html#git-repo" title="installation user's guide"&gt;user&amp;#8217;s guide&lt;/a&gt;, and then …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Tue, 19 Jul 2011 12:01:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-07-19:/blog/sparsepca-in-scikits-learn-git.html</guid><category>pca</category><category>principal components analysis</category><category>scikit-learn</category><category>sparse pca</category><category>SparsePCA</category><category>spca</category></item><item><title>K-Means for dictionary learning</title><link>http://vene.ro/blog/k-means-for-dictionary-learning.html</link><description>&lt;p&gt;[![Dictionary learned with K-Means on the &lt;span class="caps"&gt;LFW&lt;/span&gt; dataset with whitening
&lt;span class="caps"&gt;PCA&lt;/span&gt;][]][][![Dictionary learned with K-Means on the &lt;span class="caps"&gt;LFW&lt;/span&gt; dataset without
whitening &lt;span class="caps"&gt;PCA&lt;/span&gt;][]][]&lt;/p&gt;
&lt;p&gt;One of the simplest, and yet most heavily constrained form of matrix
factorization, is vector quantization (&lt;span class="caps"&gt;VQ&lt;/span&gt;). Heavily used in image/video
compression, the &lt;span class="caps"&gt;VQ&lt;/span&gt; problem is a …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 10 Jul 2011 14:27:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-07-10:/blog/k-means-for-dictionary-learning.html</guid><category>dictionary learning</category><category>k-means</category><category>scikit-learn</category><category>vq</category><category>Uncategorized</category></item><item><title>Image denoising with dictionary learning</title><link>http://vene.ro/blog/image-denoising-with-dictionary-learning.html</link><description>&lt;p&gt;I am presenting an image denoising example that fully runs under my
local scikits-learn fork. Coming soon near&amp;nbsp;you!&lt;/p&gt;
&lt;p&gt;The 400 square pixels area covering Lena&amp;#8217;s face was distorted by
additive gaussian noise with a standard deviation of 50 (pixel values
are ranged&amp;nbsp;0-256.)&lt;/p&gt;
&lt;p&gt;[&lt;img alt="Lena image denoising using dictionary learning" src="http://localhost:8001/wp-content/uploads/2011/07/denoise3.png" title="Lena denoising"&gt;][]&lt;/p&gt;
&lt;p&gt;The dictionary contains 100 atoms …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 07 Jul 2011 20:00:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-07-07:/blog/image-denoising-with-dictionary-learning.html</guid><category>denoising</category><category>dictionary learning</category><category>scikit-learn</category></item><item><title>Dictionary learning sneak peek</title><link>http://vene.ro/blog/dictionary-learning-sneak-peek.html</link><description>&lt;p&gt;Closing in on the goal of integrating J. Mairal&amp;#8217;s dictionary learning in
the scikit, I stitched together a couple of&amp;nbsp;examples.&lt;/p&gt;
&lt;p&gt;The code is not yet integrated according to our standards, but here is
the kind of results you can&amp;nbsp;expect.&lt;/p&gt;
&lt;p&gt;Here is how a dictionary obtained from 8x8 …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 24 Jun 2011 12:06:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-06-24:/blog/dictionary-learning-sneak-peek.html</guid><category>Uncategorized</category></item><item><title>Summer of Code roadmap, part 1</title><link>http://vene.ro/blog/summer-of-code-roadmap-part-1.html</link><description>&lt;p&gt;After a little busy while, I have graduated and entered the summer
vacation, which means time for serious GSoC&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;[&lt;img alt="Me on graduation day" src="http://localhost:8001/wp-content/uploads/2011/06/p1080283.jpg" title="Graduation day"&gt;][]&lt;/p&gt;
&lt;p&gt;So we had a little conference in order to discuss what will be done and
when. We gathered quite a few code snippets since the official start of
the project …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sun, 12 Jun 2011 14:28:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-06-12:/blog/summer-of-code-roadmap-part-1.html</guid><category>gsoc</category><category>Uncategorized</category></item><item><title>First thoughts on Orthogonal Matching Pursuit</title><link>http://vene.ro/blog/first-thoughts-on-orthogonal-matching-pursuit.html</link><description>&lt;p&gt;I am working on implementing the Orthogonal Matching Pursuit (&lt;span class="caps"&gt;OMP&lt;/span&gt;)
algorithm for the scikit. It is an elegant algorithm (that almost writes
itself in Numpy!) to compute a greedy approximation to the solution of a
sparse coding&amp;nbsp;problem:&lt;/p&gt;
&lt;p&gt;\$\$ \text{argmin} \big|\big|\gamma\big|\big|_0 \text{ subject
to }\big …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 30 May 2011 13:02:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-05-30:/blog/first-thoughts-on-orthogonal-matching-pursuit.html</guid><category>Uncategorized</category><category>dictionary learning</category><category>omp</category><category>orthogonal matching pursuit</category></item><item><title>Sparse PCA</title><link>http://vene.ro/blog/sparse-pca.html</link><description>&lt;p&gt;I have been working on the integration into the scikits.learn codebase
of a sparse principal components analysis (SparsePCA) algorithm coded by
Gaël and Alexandre and based on [[1]][]. Because the name &amp;#8220;sparse &lt;span class="caps"&gt;PCA&lt;/span&gt;&amp;#8221;
has some inherent ambiguity, I will describe in greater depth what
problem we are actually solving …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 23 May 2011 15:19:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-05-23:/blog/sparse-pca.html</guid><category>dictionary learning</category><category>pca</category><category>sparse pca</category><category>SparsePCA</category><category>spca</category><category>scikit-learn</category></item><item><title>Customizing scikits.learn for a specific text analysis task</title><link>http://vene.ro/blog/customizing-scikits-learn-for-a-specific-text-analysis-task.html</link><description>&lt;p&gt;Scikits.learn is a great general library, but machine learning has so
many different application, that it is often very helpful to be able to
extend its &lt;span class="caps"&gt;API&lt;/span&gt; to better integrate with your code. With scikits.learn,
this is extremely easy to do using inheritance and using the pipeline&amp;nbsp;module …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 29 Apr 2011 14:33:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-29:/blog/customizing-scikits-learn-for-a-specific-text-analysis-task.html</guid><category>nlp</category><category>scikit-learn</category></item><item><title>An overview of dictionary learning: Terminology</title><link>http://vene.ro/blog/an-overview-of-dictionary-learning-terminology.html</link><description>&lt;p&gt;My GSoC proposal is titled &amp;#8220;Dictionary learning in scikits.learn&amp;#8221; and in
the project, I plan to implement methods used in state of the art
research and industry applications in signal and image processing. In
this post, I want to clarify the terminology&amp;nbsp;used.&lt;/p&gt;
&lt;p&gt;Usually the terms &lt;em&gt;dictionary learning&lt;/em&gt; and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 15 Apr 2011 14:10:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-15:/blog/an-overview-of-dictionary-learning-terminology.html</guid><category>dictionary learning</category><category>scikit-learn</category><category>Uncategorized</category></item><item><title>Newton interpolation and numerical differentiation</title><link>http://vene.ro/blog/newton-interpolation-and-numerical-differentiation.html</link><description>&lt;p&gt;I am sharing some Python code code that I wrote as a school assignment.
This computes the Newton form of the interpolation polynomial of a given
set of points, and allows for the evaluation of both the polynomial and
its derivative, at a given point. This is an accurate way …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Fri, 15 Apr 2011 13:34:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-15:/blog/newton-interpolation-and-numerical-differentiation.html</guid><category>differentiation</category><category>interpolation</category><category>matplotlib</category><category>newton</category><category>numerical</category><category>numpy</category><category>python</category></item><item><title>A look at Romanian verbs with scikits-learn</title><link>http://vene.ro/blog/a-look-at-romanian-verbs-with-scikits-learn.html</link><description>&lt;p&gt;One of the problems we tackled here at my university is one as old as
the modern Romanian language. It is a problem for linguists, as well as
for foreigners trying to learn the language. We call it the root
alternations&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;Similar to French and other languages, Romanian verbs …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Thu, 14 Apr 2011 01:40:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-14:/blog/a-look-at-romanian-verbs-with-scikits-learn.html</guid><category>alternations</category><category>computational linguistics</category><category>infinitives</category><category>pca</category><category>principal components analysis</category><category>nlp</category><category>scikit-learn</category></item><item><title>Tweaking matplotlib subplots for pretty results</title><link>http://vene.ro/blog/tweaking-matplotlib-subplots-for-pretty-results.html</link><description>&lt;p&gt;When plotting multiple subplots using matplotlib, the axes rarely look
pretty with the default configuration. Since matplotlib figures are
abstract objects, designed for consistency in print as well as on
screen, tweaking their layout can get&amp;nbsp;tricky.&lt;/p&gt;
&lt;h3&gt;An&amp;nbsp;example&lt;/h3&gt;
&lt;p&gt;The following code is taken from the &lt;a href="http://scikit-learn.sourceforge.net/auto_examples/applications/plot_face_recognition.html" title="face recognition example"&gt;face recognition example&lt;/a&gt; in …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 04 Apr 2011 20:53:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-04:/blog/tweaking-matplotlib-subplots-for-pretty-results.html</guid><category>matplotlib</category><category>python</category></item><item><title>On setuptools subpackages</title><link>http://vene.ro/blog/on-setuptools-subpackages.html</link><description>&lt;p&gt;Today, I spent more than two hours trying to figure out why, despite
things working out fine in my development scikits.learn folder,
&lt;code&gt;python setup.py install&lt;/code&gt; would completely ignore the module I
refactored into a&amp;nbsp;subpackage.&lt;/p&gt;
&lt;p&gt;I imagined that simply adding it to the parent &lt;code&gt;__init__.py __all__&lt;/code&gt;
attribute …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Mon, 04 Apr 2011 15:01:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-04:/blog/on-setuptools-subpackages.html</guid><category>python</category><category>setuptools</category></item><item><title>My first scikits.learn coding sprint</title><link>http://vene.ro/blog/my-first-scikits-learn-coding-sprint.html</link><description>&lt;p&gt;The fifth &lt;a href="http://scikit-learn.sourceforge.net/" title="scikits.learn"&gt;scikits.learn&lt;/a&gt; coding sprint took place Friday, April 1st
2011. For anyone who is not familiar with it, scikits.learn is a fast
and easy to use machine learning toolkit for the pylab environment
(Python, NumPy, SciPy,&amp;nbsp;Matplotlib.)&lt;/p&gt;
&lt;p&gt;This was a good opportunity for me to get code …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Sat, 02 Apr 2011 20:12:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-04-02:/blog/my-first-scikits-learn-coding-sprint.html</guid><category>coding sprint</category><category>scikit-learn</category></item><item><title>About</title><link>http://vene.ro/blog/about.html</link><description>&lt;p&gt;My name is Vlad, I am a master&amp;#8217;s student at the University of Bucharest,
I work there at the Centre for Computational Linguistics, and I am a
contributor to the Python machine learning library &lt;a href="http://scikit-learn.org" title="scikit-learn"&gt;scikit-learn&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Wed, 30 Mar 2011 08:59:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-03-30:/blog/about.html</guid></item><item><title>Hello world!</title><link>http://vene.ro/blog/hello-world-2.html</link><description>&lt;p&gt;This is the blog where I will post updates regarding my work
on&lt;a href="http://scikit-learn.sourceforge.net/" title="scikits-learn"&gt;scikits-learn.&lt;/a&gt; I am applying as a GSoC 2011 student with the &lt;span class="caps"&gt;PSF&lt;/span&gt;
for work on this machine learning&amp;nbsp;library.&lt;/p&gt;
&lt;p&gt;I will also post related work that I do in the machine learning&amp;nbsp;field.&lt;/p&gt;
&lt;p&gt;I hope to prove …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">vene</dc:creator><pubDate>Wed, 30 Mar 2011 08:59:00 +0200</pubDate><guid isPermaLink="false">tag:vene.ro,2011-03-30:/blog/hello-world-2.html</guid><category>Uncategorized</category></item></channel></rss>